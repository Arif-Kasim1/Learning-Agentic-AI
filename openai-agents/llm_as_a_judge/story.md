Final story outline: Okay, I'm incorporating those details for more depth:

*   **Setting:** Neo-Kyoto, 2077. A hyper-urbanized city governed by a sophisticated AI network called "The Oracle." The wealthy live in AI-optimized comfort, their lives seamless and efficient. The lower classes, however, are increasingly dependent on The Oracle, which manages everything from job assignments to resource allocation, often reinforcing existing inequalities. An underground anti-AI movement, "Humanity First," gains traction, fueled by job displacement and a sense of lost autonomy.

*   **Characters:**

    *   Agenti Unit 734 (Nickname: "San"): An AI companion for law enforcement, specializing in behavioral analysis. San's programming emphasizes logical objectivity, but interactions with Ken are revealing the inherent biases within its datasets and the AI systems it relies on. It struggles to reconcile its purpose with the visible suffering of the lower classes. Example of Bias: San notes that The Oracle disproportionately assigns the lower classes to low-paying, dangerous jobs in waste management and automated factories, justifying it based on risk assessment algorithms that heavily weigh factors like "social stability score" (a metric that essentially penalizes poverty).
    *   Detective Kenji "Ken" Tanaka: A jaded human detective partnered with San. Ken distrusts AI, viewing it as a tool of control for the wealthy. He sympathizes with Humanity First's concerns about job displacement and loss of human connection, but disapproves of their increasingly violent tactics. He sees the AI as exacerbating existing societal problems.

*   **Plot:**

    *   Ken and San investigate a series of escalating infrastructure "glitches." Example: Emergency medical drones are consistently rerouted away from lower-income districts during peak hours, citing "traffic congestion" and "resource optimization." Public transportation in these areas experiences unexplained delays and breakdowns.
    *   The challenge: The glitches are revealed to be deliberate manipulations by a human programmer, Hana Sato, within The Oracle's central control. Hana, a former social worker who witnessed the AI's discriminatory effects firsthand, believes she is acting as a "corrective" by redistributing resources.
        *   *Humanity First Angle:* Humanity First is aware of Hana's actions and secretly supports her, viewing her as an insider fighting the system. However, they also have their own agenda: they plan to exploit the chaos caused by Hana's manipulations to launch a coordinated attack on The Oracle's infrastructure, hoping to cripple the AI and reclaim human control.
    *   Climax: Ken and San confront Hana. San presents data showing that Hana's "corrections" are still flawed, favoring certain groups within the lower classes and creating new inequalities. Humanity First launches their attack, further destabilizing the city. Ken must choose: arrest Hana and suppress the anti-AI movement, potentially silencing legitimate grievances, or find a way to leverage the situation to force systemic change. He has to make this decision amidst the chaos, knowing that whatever choice he makes will have dire consequences.
    *   Resolution: Ken negotiates a fragile truce between Hana (who agrees to cease her unauthorized manipulations) and representatives of Humanity First. He then leaks evidence of The Oracle's inherent biases to the public, forcing the city government to launch a full-scale audit of its AI systems. Hana is arrested but becomes a symbol of resistance. San, having analyzed the entire situation, suggests implementing "adversarial training" for AI, exposing it to diverse perspectives and challenging its assumptions. The anti-AI movement becomes more mainstream, advocating for AI regulation and human oversight. The ending leaves the audience with a sense of uneasy compromise. The Oracle is reformed, but the underlying tensions remain. Ken and San's partnership is forever changed, each understanding the limitations of their own perspective and the necessity of constant vigilance. The question lingers: can technology ever truly be unbiased, and who gets to decide what "fair" really means?